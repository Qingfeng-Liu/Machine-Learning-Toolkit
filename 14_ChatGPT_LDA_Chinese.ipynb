{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§  ä½¿ç”¨ChatGPTåµŒå…¥å’ŒNMFè¿›è¡Œä¸»é¢˜å»ºæ¨¡\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬æ¼”ç¤ºäº†ä¸€ä¸ªç°ä»£æ— ç›‘ç£ä¸»é¢˜å»ºæ¨¡æµç¨‹ï¼š\n",
    "\n",
    "- âœ… ä½¿ç”¨OpenAIçš„`text-embedding-3-small`æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åµŒå…¥\n",
    "- âœ… ä½¿ç”¨NMF(éè´ŸçŸ©é˜µåˆ†è§£)è¿›è¡Œä¸»é¢˜èšç±»\n",
    "- âœ… ä¸¤ç§ä¸»é¢˜è§£é‡Šæ–¹æ³•ï¼š\n",
    "    - TF-IDFå…³é”®è¯æå–\n",
    "    - åŸºäºChatGPTçš„æ‘˜è¦ç”Ÿæˆ\n",
    "\n",
    "è¿™ç§æ–¹æ³•æä¾›äº†è¯­ä¹‰ä¸»é¢˜èšç±»å’Œäººç±»å¯è¯»çš„æ‘˜è¦ã€‚"
   ],
   "id": "984830e8873aa4e4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import openai\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# è®¾ç½®æ‚¨çš„OpenAI APIå¯†é’¥\n",
    "# openai.api_key = \"OpenAI_Key\"  # æ›¿æ¢ä¸ºæ‚¨çš„çœŸå®APIå¯†é’¥\n",
    "\n",
    "# ç¤ºä¾‹æ•°æ®é›†\n",
    "data = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"ç»æµæ­£é¢ä¸´é€šèƒ€å’ŒåŠ æ¯å¸¦æ¥çš„æŒ‘æˆ˜\",\n",
    "        \"ç”±äºå¯¹ç»æµè¡°é€€çš„æ‹…å¿§ï¼Œè‚¡å¸‚ä¸€ç›´æ³¢åŠ¨ä¸å®š\",\n",
    "        \"æŠ•èµ„è€…æ­£åœ¨å¯»æ‰¾é»„é‡‘å’Œå€ºåˆ¸ç­‰é¿é™©èµ„äº§\",\n",
    "        \"æœºå™¨å­¦ä¹ ç®—æ³•æ­£åœ¨å¿«é€Ÿæ”¹è¿›\",\n",
    "        \"ç¥ç»ç½‘ç»œè¢«å¹¿æ³›åº”ç”¨äºå›¾åƒè¯†åˆ«ä»»åŠ¡\",\n",
    "        \"äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜åŒ»ç–—ä¿å¥è¡Œä¸š\",\n",
    "        \"æ–°æ¬¾iPhoneå‘å¸ƒï¼Œç”µæ± å’Œæ‘„åƒå¤´æ›´å¥½\",\n",
    "        \"ä¸‰æ˜Ÿæœ€æ–°æ‰‹æœºé‡‡ç”¨å¯æŠ˜å å±å¹•\",\n",
    "        \"ç§‘æŠ€å°ç©æ„æ˜¯èŠ‚æ—¥æœŸé—´çš„çƒ­é—¨ç¤¼ç‰©\",\n",
    "        \"ç§‘å­¦å®¶åœ¨å®œå±…å¸¦å‘ç°äº†ä¸€é¢—æ–°çš„ç³»å¤–è¡Œæ˜Ÿ\"\n",
    "    ]\n",
    "})"
   ],
   "id": "65b815ac3b0282f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€æ­¥ï¼šç”ŸæˆChatGPTåµŒå…¥å‘é‡"
   ],
   "id": "a9983185c83df58"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=text,\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# è·å–åµŒå…¥å‘é‡\n",
    "embedding_list = []\n",
    "for i, row in data.iterrows():\n",
    "    embedding = get_embedding(row['text'])\n",
    "    embedding_list.append(embedding)\n",
    "\n",
    "X = np.array(embedding_list)  # å½¢çŠ¶ (æ–‡æ¡£æ•°, 1536)"
   ],
   "id": "2e6bdbda9788fecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒæ­¥ï¼šé™ç»´(PCA) + ä¸»é¢˜å»ºæ¨¡(NMF)"
   ],
   "id": "f12b5a8e181730a"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# é™ç»´å¤„ç†\n",
    "X_reduced = PCA(n_components=100, random_state=42).fit_transform(X)\n",
    "\n",
    "# ä¸»é¢˜å»ºæ¨¡\n",
    "n_topics = 3\n",
    "nmf = NMF(n_components=n_topics, random_state=42)\n",
    "W = nmf.fit_transform(X_reduced)\n",
    "H = nmf.components_\n",
    "\n",
    "# ä¸ºæ¯ä¸ªæ–‡æ¡£åˆ†é…ä¸»è¦ä¸»é¢˜\n",
    "topic_assignments = np.argmax(W, axis=1)\n",
    "data['topic'] = topic_assignments\n",
    "\n",
    "# æ˜¾ç¤ºç»“æœ\n",
    "data[['text', 'topic']]"
   ],
   "id": "a9747ecffaaefa8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰æ­¥aï¼šæ¯ä¸ªä¸»é¢˜çš„å…³é”®è¯æå–(TF-IDF + NMF)"
   ],
   "id": "4598d3096f004a00"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== TF-IDF + NMFå…³é”®è¯æ‘˜è¦ ===\")\n",
    "n_keywords = 5\n",
    "\n",
    "for topic_id in sorted(data['topic'].unique()):\n",
    "    topic_texts = data[data['topic'] == topic_id]['text'].tolist()\n",
    "    print(f\"\\n--- ä¸»é¢˜ {topic_id} ---\")\n",
    "\n",
    "    # TF-IDF\n",
    "    vectorizer = TfidfVectorizer(max_df=0.95, min_df=1, stop_words='english')\n",
    "    tfidf = vectorizer.fit_transform(topic_texts)\n",
    "\n",
    "    # NMF\n",
    "    nmf_sub = NMF(n_components=1, random_state=0)\n",
    "    W_sub = nmf_sub.fit_transform(tfidf)\n",
    "    H_sub = nmf_sub.components_\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    top_keywords = [feature_names[i] for i in H_sub[0].argsort()[::-1][:n_keywords]]\n",
    "    print(\"Top keywords:\", \", \".join(top_keywords))"
   ],
   "id": "e9c730f02fb6350c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰æ­¥bï¼šé€šè¿‡ChatGPTç”Ÿæˆä¸»é¢˜æ‘˜è¦"
   ],
   "id": "cd44407f0cce0b1d"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"=== åŸºäºChatGPTçš„ä¸»é¢˜æ‘˜è¦ ===\")\n",
    "for topic_id in sorted(data['topic'].unique()):\n",
    "    examples = data[data['topic'] == topic_id]['text'].tolist()\n",
    "    prompt = \"æ€»ç»“ä»¥ä¸‹å¥å­çš„ä¸»é¢˜:\\n\\n\" + \"\\n\\n\".join(examples)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content\n",
    "    print(f\"\\n--- ä¸»é¢˜ {topic_id} æ‘˜è¦ ---\\n{summary}\")"
   ],
   "id": "29712787d7e1b5e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… æ€»ç»“\n",
    "\n",
    "æœ¬ç¬”è®°æœ¬å±•ç¤ºäº†å¦‚ä½•ï¼š\n",
    "\n",
    "- ä½¿ç”¨ChatGPTä¸ºçŸ­æ–‡æœ¬åˆ›å»ºæœ‰æ„ä¹‰çš„åµŒå…¥\n",
    "- ä½¿ç”¨NMFè¿›è¡Œè¯­ä¹‰èšç±»\n",
    "- ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•è§£é‡Šä¸»é¢˜ï¼š\n",
    "    - ä¼ ç»Ÿçš„TF-IDFå…³é”®è¯æå–\n",
    "    - åŸºäºLLMçš„æ‘˜è¦ç”Ÿæˆ\n",
    "\n",
    "è¿™ç§æ–¹æ³•ç»“åˆäº†LLMçš„å¼ºå¤§èƒ½åŠ›å’Œå¯è§£é‡Šæ€§ï¼Œä¸ä¾èµ–å•çº¯çš„è¯é¢‘ç»Ÿè®¡å°±èƒ½å®ç°æœ€å…ˆè¿›çš„ä¸»é¢˜å»ºæ¨¡ã€‚"
   ],
   "id": "82162957940b00e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}
