{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 日本語テキストの感情分析 (BERT)\n",
    "## 日本語対応の感情分析モデル使用例"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 必要なライブラリのインストール（初回のみ）\n",
    "# !pip install transformers torch fugashi ipadic"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from transformers import BertJapaneseTokenizer, BertForSequenceClassification\n",
    "import torch  # torch>=2.6.0\n",
    "\n",
    "# 1. 日本語用モデルとトークナイザーの読み込み\n",
    "model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "tokenizer = BertJapaneseTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 2. 3クラス分類タスク用のモデル（分類器付き）\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3,\n",
    "    id2label={0: \"negative\", 1: \"neutral\", 2: \"positive\"},\n",
    "    label2id={\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    ")\n",
    "# 3クラス分類用に変更"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 3. テスト用日本語テキスト\n",
    "japanese_texts = [\n",
    "    \"この映画は素晴らしかった！主演俳優の演技が最高でした。\",  # ポジティブ\n",
    "    \"最悪の商品です。買って後悔した。\",  # ネガティブ\n",
    "    \"普通ですね。特に良いとも悪いとも思わない。\",  # ニュートラル\n",
    "    \"レストランの料理は美味しかったですが、サービスがちょっと...\",  # 混合\n",
    "    \"昨日、東京タワーに行ってきました。景色がきれいでした。\"  # 中立（感情なし）\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(torch.__version__)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 4. 感情分析関数\n",
    "def analyze_japanese_sentiment(text):\n",
    "    # テキストをトークン化\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # モデル推論\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 確率に変換\n",
    "    probs = torch.softmax(outputs.logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs).item()\n",
    "    \n",
    "    # ラベル定義 (3クラス)\n",
    "    labels = {\n",
    "        0: \"ネガティブ\",\n",
    "        1: \"ニュートラル\", \n",
    "        2: \"ポジティブ\"\n",
    "    }\n",
    "    \n",
    "    # 結果表示\n",
    "    print(f\"\\nテキスト: '{text}'\")\n",
    "    print(f\"予測感情: {labels[predicted_class]}\")\n",
    "    print(\"確率分布:\")\n",
    "    for i, prob in enumerate(probs[0]):\n",
    "        print(f\"{labels[i]}: {prob*100:.1f}%\")\n",
    "    print(\"=\"*50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 5. すべてのテキストを分析\n",
    "for text in japanese_texts:\n",
    "    analyze_japanese_sentiment(text)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 日本語BERTモデルについての注意点\n",
    "1. この例では東北大学の日本語BERTベースモデルを使用\n",
    "2. 感情分析用にファインチューニングする必要があります（この例では未調整）\n",
    "3. より精度の高い日本語感情分析には以下がおすすめ：\n",
    "   - `daigo/bert-base-japanese-sentiment` (感情分析用ファインチューニング済み)\n",
    "   - `koheiduck/bert-japanese-finetuned-sentiment`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 6. (オプション) ファインチューニング済みモデルを使用する場合\n",
    "# !pip install sentencepiece\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# \n",
    "# finetuned_model = 'daigo/bert-base-japanese-sentiment'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(finetuned_model)\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(finetuned_model)\n",
    "# \n",
    "# # 同じanalyze_japanese_sentiment関数が使用可能"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
