{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Wage Analysis with Data Split",
   "id": "eedc13747c340c1d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "id": "84784aca9075378d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Load generated data",
   "id": "7f91540019330fc6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = pd.read_csv('./DATA/wage_data.csv')\n",
    "print(data.head())\n",
    "\n",
    "print(\"Data loaded successfully\")"
   ],
   "id": "7b832c22a86d29f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Transfer Categorical Features to dummies",
   "id": "6332c0f1e85ac631"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# One-hot encode three categorical columns with drop_first=True\n",
    "cat_cols = ['clothing_color', 'birth_month', 'favorite_number']\n",
    "\n",
    "# Fit-time: create dummies from data\n",
    "data = pd.get_dummies(data, columns=cat_cols, drop_first=True)\n",
    "print(data.head())\n",
    "print(\"The categorical features were transformed to dummy variables.\")"
   ],
   "id": "7e72f3a53825cc92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Data Splitting",
   "id": "91e4bc322aaa8aaa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X = data.drop(columns=['log_wage'])\n",
    "log_wage = data['log_wage']\n",
    "\n",
    "# Split data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, log_wage, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "for df in [X_train, X_val, X_test, y_train, y_val, y_test]:\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "print(\"Data split successfully\")"
   ],
   "id": "1c88e1a30a80fdc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Model Specifications",
   "id": "27c37292a1f844e6"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"Show list of all variables\")\n",
    "print(X_train.columns.tolist())\n",
    "\n",
    "# List of all variables\n",
    "# ['educ', 'exper', 'exper_sq', 'ability', 'female', 'union', 'height', 'commute_km', 'clothing_color_blue', 'clothing_color_gray', 'clothing_color_other', 'clothing_color_white', 'birth_month_2.0', 'birth_month_3.0', 'birth_month_4.0', 'birth_month_5.0', 'birth_month_6.0', 'birth_month_7.0', 'birth_month_8.0', 'birth_month_9.0', 'birth_month_10.0', 'birth_month_11.0', 'birth_month_12.0', 'favorite_number_2.0', 'favorite_number_3.0', 'favorite_number_4.0', 'favorite_number_5.0', 'favorite_number_6.0', 'favorite_number_7.0', 'favorite_number_8.0', 'favorite_number_9.0']\n",
    "\n",
    "model_specs = {\n",
    "    \"Basic\": ['educ', 'exper'],\n",
    "    \"Core\": ['educ', 'exper', 'ability'],\n",
    "    \"TrueDGP\": ['educ', 'exper', 'exper_sq', 'ability', 'female', 'union'],\n",
    "    \"Overfit1\": ['educ', 'exper', 'ability', 'female', 'union', 'height', 'commute_km', 'birth_month_2.0', 'birth_month_3.0', 'birth_month_4.0', 'birth_month_5.0', 'birth_month_6.0', 'birth_month_7.0', 'birth_month_8.0', 'birth_month_9.0', 'birth_month_10.0', 'birth_month_11.0', 'birth_month_12.0'],\n",
    "    \"Overfit2\": ['educ', 'exper', 'ability', 'female', 'union', \n",
    "                'height', 'birth_month_2.0', 'birth_month_3.0', 'birth_month_4.0', 'birth_month_5.0', 'birth_month_6.0', 'birth_month_7.0', 'birth_month_8.0', 'birth_month_9.0', 'birth_month_10.0', 'birth_month_11.0', 'birth_month_12.0'],\n",
    "    \"Overfit3\": ['educ', 'exper', 'ability', 'female', 'union',\n",
    "                'height', 'birth_month_2.0', 'birth_month_3.0', 'birth_month_4.0', 'birth_month_5.0', 'birth_month_6.0', 'birth_month_7.0', 'birth_month_8.0', 'birth_month_9.0', 'birth_month_10.0', 'birth_month_11.0', 'birth_month_12.0', 'clothing_color_blue', 'clothing_color_gray', 'clothing_color_other', 'clothing_color_white'],\n",
    "    \"KitchenSink\": list(set(X_train.columns))}"
   ],
   "id": "5774e43ff8e0117a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Model Evaluation",
   "id": "98189cfa500fbae3"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def evaluate_model(variables, X_train, y_train, X_val, y_val, X_test, y_test):\n",
    "    # try:\n",
    "    X_train_sm = sm.add_constant(X_train[variables])*1\n",
    "    # print(X_train_sm.head())\n",
    "    print(X_train_sm.head())\n",
    "    print(y_train.head())\n",
    "    model = sm.OLS(y_train, X_train_sm).fit()\n",
    "\n",
    "    def calc_mse(X, y):\n",
    "        X_sm = sm.add_constant(X[variables])\n",
    "        return ((y - model.predict(X_sm))**2).mean()\n",
    "\n",
    "    train_mse = calc_mse(X_train, y_train)\n",
    "    val_mse = calc_mse(X_val, y_val)\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'train_mse': train_mse,\n",
    "        'val_mse': val_mse,\n",
    "        'test_mse': calc_mse(X_test, y_test),\n",
    "        'overfit_gap': val_mse - train_mse,\n",
    "        'adj_r2': model.rsquared_adj,\n",
    "        'n_vars': len(variables)\n",
    "    }\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error in {variables}: {str(e)}\")\n",
    "    #     return None"
   ],
   "id": "4bd5c5bb0aae4bed",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Train and Evaluate Models",
   "id": "37897ca0409eb150"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model_performance = {}\n",
    "for name, vars in model_specs.items():\n",
    "    result = evaluate_model(vars, X_train, y_train, X_val, y_val, X_test, y_test)\n",
    "    model_performance[name] = result\n",
    "    print(f\"{name:12} | Vars: {len(vars):2} | Val MSE: {result['val_mse']:.4f} | Gap: {result['overfit_gap']:.4f}\")"
   ],
   "id": "af034a443185f2b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results Analysis\n",
    "\n",
    "### Overfit Gap\n",
    "\n",
    "#### What it means:\n",
    "The difference between a model's performance on training data vs. validation/test data (Validation MSE - Training MSE). It measures how much worse the model performs on unseen data.\n",
    "\n",
    "#### How to interpret it:\n",
    "\n",
    "Gap Size\tInterpretation\n",
    "< 0.001\tMinimal overfitting\n",
    "0.001-0.003\tModerate overfitting\n",
    "> 0.003\tSevere overfitting\n",
    "In our visualization:\n",
    "\n",
    "Shown as red bars growing taller for more complex models\n",
    "The \"KitchenSink\" model has the largest gap\n",
    "The \"TrueDGP\" model has the smallest gap"
   ],
   "id": "ddf2bc99ac8b7830"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': name,\n",
    "        'Num Vars': perf['n_vars'],\n",
    "        'Train MSE': perf['train_mse'],\n",
    "        'Val MSE': perf['val_mse'],\n",
    "        'Test MSE': perf['test_mse'],\n",
    "        'Overfit Gap': perf['overfit_gap'],\n",
    "        'Adj R2': perf['adj_r2']\n",
    "    }\n",
    "    for name, perf in model_performance.items()\n",
    "]).sort_values('Val MSE')\n",
    "\n",
    "def highlight_overfit(val):\n",
    "    color = 'red' if val > 0.003 else ('orange' if val > 0.001 else 'green')\n",
    "    return f'background-color: {color}'\n",
    "\n",
    "display(results_df.style.format({\n",
    "    'Train MSE': '{:.4f}',\n",
    "    'Val MSE': '{:.4f}',\n",
    "    'Test MSE': '{:.4f}',\n",
    "    'Overfit Gap': '{:.4f}',\n",
    "    'Adj R2': '{:.4f}'\n",
    "}).map(highlight_overfit, subset=['Overfit Gap']))"
   ],
   "id": "8d580148c56d748c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualization"
   ],
   "id": "bbe2a23dc3a9ebd1"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Set global font sizes (affects all text elements)\n",
    "plt.rcParams.update({\n",
    "    'font.size': 16,          # Base font size (originally 8-10)\n",
    "    'axes.titlesize': 20,     # Title font size (originally 10)\n",
    "    'axes.labelsize': 18,     # Axis label font size (originally 9)\n",
    "    'xtick.labelsize': 16,    # X-axis tick label size (originally 8)\n",
    "    'ytick.labelsize': 16,    # Y-axis tick label size (originally 8)\n",
    "    'legend.fontsize': 16     # Legend font size (originally 10)\n",
    "})\n",
    "\n",
    "models = results_df['Model']\n",
    "x = np.arange(len(models))\n",
    "width = 0.2\n",
    "\n",
    "# Create bars (colors remain the same)\n",
    "train_bars = plt.bar(x - width, results_df['Train MSE'], width,\n",
    "                    color='royalblue', label='Train MSE')\n",
    "\n",
    "val_bars = plt.bar(x, results_df['Val MSE'], width,\n",
    "                  color='orange', label='Val MSE')\n",
    "\n",
    "gap_bars = plt.bar(x + width, results_df['Overfit Gap'], width,\n",
    "                  color='red', label='Overfit Gap')\n",
    "\n",
    "# Set labels and title (font sizes set globally via rcParams)\n",
    "plt.xlabel('Models', labelpad=10)  # Increased label padding\n",
    "plt.ylabel('Mean Squared Error', labelpad=10)\n",
    "plt.title('Model Performance: Clear Overfitting Pattern Emerges', pad=20)\n",
    "\n",
    "# Configure x-axis ticks\n",
    "plt.xticks(x, models, rotation=45, ha='right')  # Right-aligned rotated labels\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels (with larger font)\n",
    "for i in x:\n",
    "    plt.text(i - width, results_df.iloc[i]['Train MSE'] + 0.001,\n",
    "             f\"{results_df.iloc[i]['Train MSE']:.4f}\",\n",
    "             ha='center', va='bottom', fontsize=14)  # Slightly smaller than titles\n",
    "\n",
    "    plt.text(i, results_df.iloc[i]['Val MSE'] + 0.001,\n",
    "             f\"{results_df.iloc[i]['Val MSE']:.4f}\",\n",
    "             ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "    plt.text(i + width, results_df.iloc[i]['Overfit Gap'] + 0.001,\n",
    "             f\"+{results_df.iloc[i]['Overfit Gap']:.4f}\",\n",
    "             ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping\n",
    "plt.show()"
   ],
   "id": "93031f7f1f583b29",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "best_model_name = results_df.iloc[0]['Model']\n",
    "best_model = model_performance[best_model_name]\n",
    "\n",
    "print(f\"\\n=== Best Performing Model ===\\n{best_model_name}\")\n",
    "print(f\"Variables: {model_specs[best_model_name]}\")\n",
    "print(f\"Validation MSE: {best_model['val_mse']:.4f}\")\n",
    "print(f\"Overfit Gap: {best_model['overfit_gap']:.4f}\")\n",
    "\n",
    "print(\"\\n=== Worst Performing Model ===\")\n",
    "worst_model_name = results_df.iloc[-1]['Model']\n",
    "worst_model = model_performance[worst_model_name]\n",
    "print(f\"{worst_model_name} (Val MSE: {worst_model['val_mse']:.4f})\")\n",
    "print(f\"Included {worst_model['n_vars']} variables vs {best_model['n_vars']} in best model\")"
   ],
   "id": "b24c486b6d03975d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 }
}
