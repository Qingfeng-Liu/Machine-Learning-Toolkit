{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T02:22:30.730765Z",
     "start_time": "2025-07-30T02:22:30.707844Z"
    }
   },
   "source": [
    "# !pip install sudachipy sudachidict_core\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import re\n",
    "\n",
    "# --- Step 1: 生成 input.txt（ファイルは自動で保存・閉じる）---\n",
    "# sample_text = \"\"\"\n",
    "# 人工知能は急速に進化しています。自然言語処理も重要な研究分野の一つですか？\n",
    "# しかし、日本語には多くの課題が残っている。今後の改善が期待されているでしょう。\n",
    "# \"\"\"\n",
    "#\n",
    "# file_path = \"input.txt\"\n",
    "#\n",
    "# with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#     f.write(sample_text.strip())\n",
    "# ↑ この段階でファイルは保存され、閉じられる\n",
    "\n",
    "# --- Step 2: SudachiPy を用いた文分割と単語数分析 ---\n",
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import re\n",
    "\n",
    "# トークナイザー初期化\n",
    "tokenizer_obj = dictionary.Dictionary().create()\n",
    "mode = tokenizer.Tokenizer.SplitMode.C\n",
    "\n",
    "# ファイルから読み込み\n",
    "file_path = \"input.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# 文単位に分割（句点などで）\n",
    "sentences = re.split(r'[。！？]\\s*', text.strip())\n",
    "sentences = [s for s in sentences if s]\n",
    "\n",
    "# 分析と出力\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    tokens = tokenizer_obj.tokenize(sentence, mode)\n",
    "    words = [m.surface() for m in tokens if m.surface().strip()]\n",
    "    print(f\"第{i}文：{sentence}\")\n",
    "    print(f\"単語数：{len(words)}\")\n",
    "    print(f\"分かち書き：{' '.join(words)}\\n\")\n",
    "\n",
    "# 文単位に分割\n",
    "sentences = re.split(r'[。！？]\\s*', text.strip())\n",
    "sentences = [s for s in sentences if s]\n",
    "\n",
    "# 敬語→常体変換関数（簡易版）\n",
    "def convert_to_plain(sentence):\n",
    "    tokens = tokenizer_obj.tokenize(sentence, mode)\n",
    "    surfaces = [m.surface() for m in tokens]\n",
    "\n",
    "    # 基本の文末変換ルール（※非常に簡易）\n",
    "    joined = ''.join(surfaces)\n",
    "    if joined.endswith(\"です\"):\n",
    "        return joined[:-2] + \"である\"\n",
    "    elif joined.endswith(\"でした\"):\n",
    "        return joined[:-3] + \"であった\"\n",
    "    elif joined.endswith(\"ます\"):\n",
    "        return joined[:-2] + \"る\"\n",
    "    elif joined.endswith(\"ました\"):\n",
    "        return joined[:-3] + \"た\"\n",
    "    elif joined.endswith(\"ください\"):\n",
    "        return joined[:-4] + \"るとよい\"\n",
    "    else:\n",
    "        return joined  # 変換しない（または追加）\n",
    "\n",
    "# 変換と表示\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    converted = convert_to_plain(sent)\n",
    "    print(f\"第{i}文（元）: {sent}\")\n",
    "    print(f\"第{i}文（常体）: {converted}\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1文：人工知能は急速に進化しています\n",
      "単語数：9\n",
      "分かち書き：人工知能 は 急速 に 進化 し て い ます\n",
      "\n",
      "第2文：自然言語処理も重要な研究分野の一つですか\n",
      "単語数：11\n",
      "分かち書き：自然言語処理 も 重要 な 研究 分野 の 一 つ です か\n",
      "\n",
      "第3文：しかし、日本語には多くの課題が残っている\n",
      "単語数：12\n",
      "分かち書き：しかし 、 日本語 に は 多く の 課題 が 残っ て いる\n",
      "\n",
      "第4文：今後の改善が期待されているでしょう\n",
      "単語数：10\n",
      "分かち書き：今後 の 改善 が 期待 さ れ て いる でしょう\n",
      "\n",
      "第1文（元）: 人工知能は急速に進化しています\n",
      "第1文（常体）: 人工知能は急速に進化している\n",
      "\n",
      "第2文（元）: 自然言語処理も重要な研究分野の一つですか\n",
      "第2文（常体）: 自然言語処理も重要な研究分野の一つですか\n",
      "\n",
      "第3文（元）: しかし、日本語には多くの課題が残っている\n",
      "第3文（常体）: しかし、日本語には多くの課題が残っている\n",
      "\n",
      "第4文（元）: 今後の改善が期待されているでしょう\n",
      "第4文（常体）: 今後の改善が期待されているでしょう\n",
      "\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
