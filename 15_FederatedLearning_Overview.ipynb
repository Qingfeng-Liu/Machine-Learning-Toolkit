{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f76cef",
   "metadata": {},
   "source": [
    "# Federated Learning (FL) Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523a780",
   "metadata": {},
   "source": [
    "\n",
    "**What is Federated Learning?**  \n",
    "Federated Learning (FL) is a decentralized machine learning framework in which multiple clients (e.g., mobile devices, organizations) collaboratively train a shared global model **without exchanging their raw data**. Each client keeps its local dataset $ D_i $ private and communicates only model updates with a central server.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1449d5f7",
   "metadata": {},
   "source": [
    "### **Basic FedAvg Algorithm**\n",
    "\n",
    "In its simplest form, Federated Learning follows the Federated Averaging (FedAvg) protocol. Here's how it works:\n",
    "\n",
    "1. The server initializes a global model with parameters $w^{(t)}$.\n",
    "2. Each client $i \\in \\{1, \\ldots, N\\}$ receives this model and performs local training on its own data $D_i$, resulting in updated weights $w_i^{(t)}$.\n",
    "3. These updated weights are sent back to the server.\n",
    "4. The server aggregates them using (typically) weighted averaging:\n",
    "\n",
    "$$\n",
    "w^{(t+1)} = \\sum_{i=1}^{N} \\frac{n_i}{\\sum_{j=1}^{N} n_j} w_i^{(t)}\n",
    "$$\n",
    "\n",
    "Here, $n_i$ is the number of samples at client $i$, ensuring that clients with more data have greater influence on the global model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabe4d72",
   "metadata": {},
   "source": [
    "\n",
    "### **Key Characteristics**\n",
    "\n",
    "- **Privacy-Preserving:** Raw data stays on local devices, supporting data sovereignty and confidentiality.  \n",
    "- **Communication-Efficient:** Only model parameters are exchanged between clients and the server, not data.  \n",
    "- **Scalable:** FL can support thousands or even millions of clients in practical applications.  \n",
    "- **Resilient:** Can operate under partial client participation and intermittent connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdcd078",
   "metadata": {},
   "source": [
    "\n",
    "### **Reference**\n",
    "\n",
    "- McMahan, B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2017).  \n",
    "  **“Communication-Efficient Learning of Deep Networks from Decentralized Data.”**  \n",
    "  *Proceedings of AISTATS 2017.*  \n",
    "  [https://arxiv.org/abs/1602.05629](https://arxiv.org/abs/1602.05629)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
